{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1732181925083,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "NZLKEFGqpkza"
   },
   "outputs": [],
   "source": [
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kMDITdMpkzc"
   },
   "source": [
    "# Map Reduce\n",
    "\n",
    "In the part of the assignment you are requested to use Map Reduce paradigm to solve the following exercises.\n",
    "\n",
    "**NOTE THAT**: **A solution that does not use map reduce is not valid!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UvFKq5Dpkzd"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "You have a list of dictionaries, each representing a student with the following properties: a name and an array of test scores. Your task is to use map, filter, and reduce to calculate the average test score for each student, and then return a list of dictionaries containing only the students whose average score is above 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XnZxeOdtpkze"
   },
   "outputs": [],
   "source": [
    "students = [\n",
    "    {\"name\": \"Alice\", \"scores\": [95, 92, 88, 100]},\n",
    "    {\"name\": \"Bob\", \"scores\": [78, 81, 85, 80]},\n",
    "    {\"name\": \"Charlie\", \"scores\": [99, 91, 94, 96]},\n",
    "    {\"name\": \"Diana\", \"scores\": [85, 87, 89, 83]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WopOVxHSpkzf"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JGYCqweYpkzf",
    "outputId": "89230ab4-a15a-4ae5-84a3-9eb13573a4a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Alice', 'average_score': 93.75},\n",
       " {'name': 'Charlie', 'average_score': 95.0}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"name\": \"Alice\", \"average_score\": 93.75},\n",
    "    {\"name\": \"Charlie\", \"average_score\": 95.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG5h3pN1pkzg"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1732181928585,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "3ZB3sFT_pkzh",
    "outputId": "cf486e14-4d6f-455d-8f69-19096dfe9831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Student 1', 'scores': [90, 63, 73, 54, 99, 87]},\n",
       " {'name': 'Student 2', 'scores': [80, 67, 60, 82, 90]},\n",
       " {'name': 'Student 3', 'scores': [64, 70, 88]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student {i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "random_student_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MHi3FLeWpkzi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Student 25', 'average_score': 90.66666666666667}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "def map_func(dct):\n",
    "    su = functools.reduce(s, dct[\"scores\"])\n",
    "    av = su / len(dct[\"scores\"])\n",
    "    dct.pop(\"scores\")\n",
    "    dct[\"average_score\"] = av\n",
    "    return dct\n",
    "\n",
    "def filter_func(dct):\n",
    "    return dct[\"average_score\"] > 90\n",
    "    \n",
    "def s(x,y):\n",
    "    return (x+y)\n",
    "    \n",
    "l = random_student_dataset\n",
    "list(map(map_func, l))\n",
    "list(filter(filter_func, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWL_3xWNpkzj"
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "You have a list of dictionaries, each representing a product with the following properties: name, price, and category. Using the functions `map`, `filter`, and `reduce`, calculate the average price of the products in each category and return a list of dictionaries containing only the categories where the average price exceeds 50.\n",
    "\n",
    "Example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wwk7f8Ihpkzk"
   },
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"name\": \"Product A\", \"price\": 60, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product B\", \"price\": 40, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product C\", \"price\": 70, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product D\", \"price\": 30, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product E\", \"price\": 90, \"category\": \"Sports\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agz3cP7Ppkzl"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LbFtUV_apkzl",
    "outputId": "745cdcbe-7320-4a08-de7b-0e1bcb84473e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'Electronics', 'average_price': 50.0},\n",
       " {'category': 'Sports', 'average_price': 90.0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"category\": \"Electronics\", \"average_price\": 50.0},\n",
    "    {\"category\": \"Sports\", \"average_price\": 90.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKBEAQE3pkzl"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1732181933353,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "0qj_9nZSpkzm",
    "outputId": "7bab35c7-84d0-4603-a1da-dc4a76768179"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Product 1', 'price': 176, 'category': 'Sports'},\n",
       " {'name': 'Product 2', 'price': 16, 'category': 'Clothing'},\n",
       " {'name': 'Product 3', 'price': 13, 'category': 'Electronics'},\n",
       " {'name': 'Product 4', 'price': 31, 'category': 'Clothing'},\n",
       " {'name': 'Product 5', 'price': 90, 'category': 'Toys'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_product_dataset(num_products=100):\n",
    "    categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Product {i}\",\n",
    "            \"price\": randint(10, 200),  # Random price between 10 and 200\n",
    "            \"category\": choice(categories),  # Randomly choose a category\n",
    "        }\n",
    "        for i in range(1, num_products + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "# Example of using the function\n",
    "random_dataset = generate_random_product_dataset(100)\n",
    "random_dataset[:5]  # Display the first 5 entries to check the dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AG9V3Wt7pkzm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'Electronics', 'average_price': 85.53333333333333},\n",
       " {'category': 'Home', 'average_price': 107.9090909090909},\n",
       " {'category': 'Sports', 'average_price': 114.0625},\n",
       " {'category': 'Books', 'average_price': 112.61111111111111},\n",
       " {'category': 'Clothing', 'average_price': 94.05263157894737},\n",
       " {'category': 'Toys', 'average_price': 97.47619047619048}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hints: 1) Group products by category (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average price for each category and filter categories with an average price > 50\n",
    "\n",
    "import functools\n",
    "\n",
    "def map_func(dct):\n",
    "    su = functools.reduce(s, dct[\"price\"])\n",
    "    av = su / len(dct[\"price\"])\n",
    "    return {'category' : dct['category'], \"average_price\" : av}\n",
    "  \n",
    "def s(x,y):\n",
    "    return (x+y)\n",
    "\n",
    "def filter_func(dict):\n",
    "    return dict[\"average_price\"] > 50\n",
    "\n",
    "categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]    \n",
    "\n",
    "Electronics = []\n",
    "Home = []\n",
    "Sports = []\n",
    "Books = []\n",
    "Clothing = []\n",
    "Toys = []\n",
    "for dct in random_dataset:\n",
    "    if dct[\"category\"] == 'Electronics':\n",
    "        Electronics.append(dct['price'])\n",
    "    elif dct['category'] == 'Home':\n",
    "        Home.append(dct['price'])\n",
    "    elif dct['category'] == 'Sports':\n",
    "        Sports.append(dct['price'])\n",
    "    elif dct['category'] == 'Books':\n",
    "        Books.append(dct['price'])\n",
    "    elif dct['category'] == 'Clothing':\n",
    "        Clothing.append(dct['price'])\n",
    "    elif dct['category'] == 'Toys':\n",
    "        Toys.append(dct['price'])\n",
    "l = [{'category' : 'Electronics', 'price' : Electronics},\n",
    "     {'category' : 'Home', 'price' : Home},\n",
    "     {'category' : 'Sports', 'price' : Sports},\n",
    "     {'category' : 'Books', 'price' : Books},\n",
    "     {'category' : 'Clothing', 'price' : Clothing},\n",
    "     {'category' : 'Toys', 'price' : Toys},\n",
    "    ]\n",
    "    \n",
    "new_l = list(map(map_func, l))\n",
    "list(filter(filter_func, new_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hivtZEf7pkzm"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "You have a list of dictionaries, each representing an employee with the following properties: name, salary, and department. Your task is to use `map`, `filter`, and `reduce` to calculate the average salary for each department and return a list of dictionaries containing only the departments where the average salary is above 65,000.\n",
    "\n",
    "**Example Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1732181936402,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "N8vjLRHxpkzm"
   },
   "outputs": [],
   "source": [
    "employees = [\n",
    "    {\"name\": \"John\", \"salary\": 70000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Jane\", \"salary\": 75000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Alice\", \"salary\": 60000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Bob\", \"salary\": 68000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Charlie\", \"salary\": 90000, \"department\": \"Marketing\"},\n",
    "    {\"name\": \"Diana\", \"salary\": 50000, \"department\": \"Marketing\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otSniMO7pkzm"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Kx4HT8RXpkzn",
    "outputId": "8653ff13-815d-4040-c68e-fc4a6825134d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'department': 'Engineering', 'average_salary': 72500.0},\n",
       " {'department': 'Marketing', 'average_salary': 70000.0}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"department\": \"Engineering\", \"average_salary\": 72500.0},\n",
    "    {\"department\": \"Marketing\", \"average_salary\": 70000.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD_xlB78pkzn"
   },
   "source": [
    "### Test\n",
    "\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1732181939215,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "RhR9JLK-pkzn",
    "outputId": "72bc934d-4d3c-477e-cf84-3cf1d8fae61a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Employee 1', 'salary': 45193, 'department': 'Finance'},\n",
       " {'name': 'Employee 2', 'salary': 78770, 'department': 'Marketing'},\n",
       " {'name': 'Employee 3', 'salary': 102200, 'department': 'Finance'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_employee_dataset(num_employees=50):\n",
    "    departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Employee {i}\",\n",
    "            \"salary\": randint(40000, 120000),  # Random salary between 40,000 and 120,000\n",
    "            \"department\": choice(departments)  # Randomly choose a department\n",
    "        }\n",
    "        for i in range(1, num_employees + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_employee_dataset = generate_random_employee_dataset(50)\n",
    "\n",
    "random_employee_dataset[:3]  # Display the first 3 entries of each dataset for checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pt9m6NK-pkzo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'department': 'Engineering', 'average_salary': 95759.75},\n",
       " {'department': 'HR', 'average_salary': 80749.6},\n",
       " {'department': 'Marketing', 'average_salary': 77232.83333333333},\n",
       " {'department': 'Sales', 'average_salary': 82163.8},\n",
       " {'department': 'Finance', 'average_salary': 80659.33333333333},\n",
       " {'department': 'IT', 'average_salary': 90070.4}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold\n",
    "\n",
    "import functools\n",
    "\n",
    "def map_func(dct):\n",
    "    su = functools.reduce(s, dct[\"salary\"])\n",
    "    av = su / len(dct[\"salary\"])\n",
    "    return {'department' : dct['department'], \"average_salary\" : av}\n",
    "  \n",
    "def s(x,y):\n",
    "    return (x+y)\n",
    "\n",
    "def filter_func(dict):\n",
    "    return dict[\"average_salary\"] > 65000\n",
    "\n",
    "departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "\n",
    "Engineering = []\n",
    "HR = []\n",
    "Marketing = []\n",
    "Sales = []\n",
    "Finance = []\n",
    "IT = []\n",
    "for dct in random_employee_dataset:\n",
    "    if dct[\"department\"] == 'Engineering':\n",
    "        Engineering.append(dct['salary'])\n",
    "    elif dct['department'] == 'HR':\n",
    "        HR.append(dct['salary'])\n",
    "    elif dct['department'] == 'Marketing':\n",
    "        Marketing.append(dct['salary'])\n",
    "    elif dct['department'] == 'Sales':\n",
    "        Sales.append(dct['salary'])\n",
    "    elif dct['department'] == 'Finance':\n",
    "        Finance.append(dct['salary'])\n",
    "    elif dct['department'] == 'IT':\n",
    "        IT.append(dct['salary'])\n",
    "l = [{'department' : 'Engineering', 'salary' : Engineering},\n",
    "     {'department' : 'HR', 'salary' : HR},\n",
    "     {'department' : 'Marketing', 'salary' : Marketing},\n",
    "     {'department' : 'Sales', 'salary' : Sales},\n",
    "     {'department' : 'Finance', 'salary' : Finance},\n",
    "     {'department' : 'IT', 'salary' : IT},\n",
    "    ]\n",
    "    \n",
    "new_l = list(map(map_func, l))\n",
    "list(filter(filter_func, new_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzxr0v2Rpkzo"
   },
   "source": [
    "# Biopython\n",
    "\n",
    "Write the following five functions to analyze global alignments between two sequences using Biopython's `pairwise2` module:\n",
    "\n",
    "1. **countMatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment (pairwise2.globalxx) of the same length. It returns the number of positions where the elements of both sequences match.\n",
    "\n",
    "2. **countMismatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of positions where the elements of the two sequences are different (i.e., they are not gaps, and the characters do not match).\n",
    "\n",
    "3. **countGapOpens(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap openings in the alignment (a gap is opened when a '-' appears in the sequence).\n",
    "\n",
    "4. **countGapExtensions(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap extensions (where '-' continues in the alignment after an initial gap is opened).\n",
    "\n",
    "5. **getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment and returns the alignment score based on the provided scoring scheme: `matchScore` for matches, `mismatchPenalty` for mismatches, `gapOpenPenalty` for opening a gap, and `gapExtensionPenalty` for extending a gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5PIaf6BUpkzo"
   },
   "outputs": [],
   "source": [
    "# Add your functions here\n",
    "def countMatches(s1, s2):\n",
    "    c = 0\n",
    "    for i in range(0, len(s1)):\n",
    "        if s1[i] == s2[i]:\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def countMismatches(s1,s2):\n",
    "    c = 0\n",
    "    for i in range(0, len(s1)):\n",
    "        if s1[i] != s2[i] and s1[i] != '-' and s2[i] != '-':\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def countGapOpens(s1,s2):\n",
    "    c = 0\n",
    "    for i in range(0, len(s1)):\n",
    "        if (s1[i] == '-' and s1[i-1] != '-') or (s2[i] == '-' and s2[i-1] != '-'):\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def countGapExtensions(s1,s2):\n",
    "    c = 0\n",
    "    for i in range(0, len(s1)):\n",
    "        if (s1[i] == '-' and s1[i-1] == '-') or (s2[i] == '-' and s2[i-1] == '-'):\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty):\n",
    "    return countMatches(s1,s2) * matchScore + countMismatches(s1,s2) * mismatchPenalty + countGapOpens(s1,s2) * gapOpenPenalty + countGapExtensions(s1,s2) * gapExtensionPenalty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81O19v1fpkzo"
   },
   "source": [
    "### Test\n",
    "Align the sequences of the [Interleukin-12](https://en.wikipedia.org/wiki/Interleukin_12) chain A (denoted as `s1`) from the file [`IL12A.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12A.fasta) and the Interleukin-12 chain B (denoted as `s2`) from the file [`IL12B.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12B.fasta) and check the score as computed from pairwise2 and from your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZBhfr3jepkzp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise2: -598.0\n",
      "getScore function: -598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\Bio\\pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# add the output of the test here\n",
    "from Bio import SeqIO\n",
    "l =[]\n",
    "with open('IL12A.fasta') as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        l.append(str(record.seq))\n",
    "        \n",
    "with open('IL12B.fasta') as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        l.append(str(record.seq))\n",
    "\n",
    "v = l[0]\n",
    "w = l[1]\n",
    "  \n",
    "matchScore = 1\n",
    "mismatchPenalty = -1\n",
    "gapOpenPenalty = -5\n",
    "gapExtensionPenalty = -5\n",
    "\n",
    "from Bio import pairwise2\n",
    "alignments = pairwise2.align.globalms(v, w, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)\n",
    "\n",
    "s1 = alignments[0][0]\n",
    "s2 = alignments[0][1]\n",
    "score = alignments[0][2]\n",
    "print(f\"pairwise2: {score}\")\n",
    "\n",
    "\n",
    "score = getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)\n",
    "print(f\"getScore function: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rosalind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 228 323 431 547 561 736 737 771 780 969 1043 1186 1218 1279 1350 1381 1400 1401 1427 1465 1489 1505 1539 1547 1561 1594 1666 1705 1734 1782 1818 1965 1980 2101 2132 2143 2268 2277 2286 2293 2336 2415 2639 2709 2818 2904 2937 3065 3127 3128 3211 3231 3246 3430 3520 3548 3566 3569 3591 3613 3626 3648 3676 3698 3775 3798 3817 3903 3915 3979 3989 4023 4043 4092 4120 4143 4170 4223 4237 4269 4325 4352 4386 4463 4585 4586 4614 4684 4773 4777 4829 4846 4897 4904 4992 5014 5050 5052 5088 5105 5220 5292 5294 5480 5554 5555 5556 5569 5608 5681 5715 5732 5791 5830 5832 5849 5936 5943 5981 6001 6052 6073 6096 6167 6216 6249 6272 6305 6381 6424 6433 6488 6537 6543 6544 6569 6576 6579 6629 6667 6684 6862 6921 6942 6996 7053 7056 7214 7265 7397 7419 7429 7485 7507 7564 7655 7759 7836 7861 7883 7897 7946 8011 8063 8077 8078 8088 8173 8222 8285 8352 8444 8512 8583 8603 8615 8636 8641 8649 8763 8847 8935 8947\n",
      "8884 8860 8801 8680 8622 8609 8522 8490 8399 8394 8382 8328 8202 8179 8121 8094 8033 8009 7860 7736 7714 7701 7684 7682 7676 7615 7609 7575 7563 7549 7536 7503 7258 7234 7225 7219 7131 7119 7048 6927 6713 6690 6683 6635 6467 6412 6405 6394 6223 6203 6201 6097 5950 5922 5823 5771 5719 5674 5673 5659 5637 5596 5572 5564 5546 5516 5507 5451 5421 5351 5262 5247 5152 5123 5075 5070 5049 4981 4954 4909 4776 4704 4618 4585 4537 4472 4434 4361 4275 4209 4188 4133 4127 4073 4029 3931 3872 3811 3749 3715 3653 3650 3634 3623 3604 3575 3565 3528 3525 3487 3477 3465 3452 3367 3319 3236 3165 3152 3139 3110 3098 3061 3041 3031 2960 2930 2885 2755 2703 2642 2623 2591 2556 2468 2418 2367 2223 2179 2121 2097 2071 2037 1836 1825 1821 1703 1698 1694 1673 1668 1588 1471 1404 1393 1338 1321 1277 1249 1239 1200 1143 1113 1109 1065 1045 1026 1006 998 944 827 681 647 602 491 454 418 375 348 272 250 199 153 127 101 62\n"
     ]
    }
   ],
   "source": [
    "filein = open('rosalind_lgis.txt', encoding = 'UTF-8')\n",
    "n = int(filein.readline())\n",
    "perm = filein.readline()\n",
    "l1 = perm.split(' ')\n",
    "l = []\n",
    "for elem in l1:\n",
    "    l.append(int(elem))\n",
    "    \n",
    "matrix = []\n",
    "matrix_list = []\n",
    "\n",
    "for i in range(0, n):\n",
    "    matrix.append(1)\n",
    "    matrix_list.append([l[i]])\n",
    "    for j in range(0, i):\n",
    "        if l[j] < l[i]:\n",
    "            matrix[i] = max(matrix[i], matrix[j] + 1)\n",
    "            if len(matrix_list[i]) <= len(matrix_list[j]):\n",
    "                matrix_list[i] = matrix_list[j] + [l[i]]\n",
    "    \n",
    "out = ''\n",
    "for elem in matrix_list[matrix.index(max(matrix))]:\n",
    "    out = out + str(elem) + ' '\n",
    "out = out[0:len(out)-1] + '\\n'\n",
    "\n",
    "matrix = []\n",
    "matrix_list = []\n",
    "\n",
    "for i in range(0, n):\n",
    "    matrix.append(1)\n",
    "    matrix_list.append([l[i]])\n",
    "    for j in range(0, i):\n",
    "        if l[j] > l[i]:\n",
    "            matrix[i] = max(matrix[i], matrix[j] + 1)\n",
    "            if len(matrix_list[i]) <= len(matrix_list[j]):\n",
    "                matrix_list[i] = matrix_list[j] + [l[i]]\n",
    "\n",
    "for elem in matrix_list[matrix.index(max(matrix))]:\n",
    "    out = out + str(elem) + ' '\n",
    "out = out[0:len(out)-1]\n",
    "print(out)\n",
    "    \n",
    "filein.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10 12 17 18 29 34 37 41 43 47 48 60 63 67 68 70 73 76 80 85 87 89 90 92 94 95 106 107 112 116 118 122 123 126 131 136 146 148 151 153 155 158 165 167 173 174 177 190 193 194 208 216 220 233 234 236\n"
     ]
    }
   ],
   "source": [
    "filein = open('rosalind_sseq.txt', encoding = 'UTF-8')\n",
    "l = []\n",
    "i = -1\n",
    "for line in filein:\n",
    "    if '>' in line:\n",
    "        i = i+1\n",
    "        l.append('')\n",
    "        continue\n",
    "    else:\n",
    "        l[i] = l[i] + line.replace('\\n', '')\n",
    "\n",
    "out = ''\n",
    "temp = 0\n",
    "for c in l[1]:\n",
    "    i = l[0].index(c, temp)\n",
    "    temp = i + 1\n",
    "    out = out + str(i+1) + ' '\n",
    "\n",
    "filein.close()\n",
    "print(out[0:len(out)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lcsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGGCAGGAACCTGAAATGGGTGGTCAGTGGCTAAAGTCGAATCAAACTTCGCACTTACCCTTCTAGTCGAAACCGTTTCACTGAATGCACTGAGTCCGTGTTAAGGAGTTGTCGGGGTTAAACAGAACCAAATCCCCCTCACAATCCCATCTCGGAGAGGGAGGGGGGCGTCAGCCCCCTCATGTATTTAGCACTGGGGTAGCTCCACTTGTGGACTTTCCTCACCAGGGGTTCAAAACTAAGTGGTTGGTGCCGGACGCAGTTCTGTTCCAGAACTCGTTGGGAGTCAGTCTTGTGGTTGACAAACTTTTTAAGATCTTCCGGCCGAAACGACTTTTCGGTTAAAAATTTTTTGGGATTATTTTGTTCTAAATACACTGGTCGACTTGGAAAGGAGCTGACACGAGTAGCAATGATCCCTAAGGTAATGAAACCACTATGCTGGGTTCCGCAACAAGTCAGTACATTCCCTGATAAATTTGTGGTTGGGCACGGGTGGGGCCTGGGTTTTGGCTTGTCAAGAGCCAATGGTTCTTATAATCCGTTGATTGCGG\n"
     ]
    }
   ],
   "source": [
    "filein = open('rosalind_lcsq.txt', encoding = 'UTF-8')\n",
    "l = []\n",
    "i = -1\n",
    "for line in filein:\n",
    "    if '>' in line:\n",
    "        i = i+1\n",
    "        l.append('')\n",
    "        continue\n",
    "    else:\n",
    "        l[i] = l[i] + line.replace('\\n', '')\n",
    "\n",
    "v = l[0]\n",
    "w = l[1]\n",
    "n = len(v)\n",
    "m = len(w)\n",
    "matrix = []\n",
    "b = []\n",
    "out = ''\n",
    "\n",
    "for i in range(0, n+1):\n",
    "    matrix.append([0]*(m+1))\n",
    "    b.append(['']*(m+1))\n",
    "    \n",
    "for i in range(1, n+1):\n",
    "    for j in range(1, m+1):\n",
    "        if v[i-1] == w[j-1]:\n",
    "            matrix[i][j] = matrix[i-1][j-1] + 1\n",
    "            b[i][j] = 'NW'\n",
    "        elif matrix[i-1][j] >= matrix[i][j-1]:\n",
    "            matrix[i][j] = matrix[i-1][j]\n",
    "            b[i][j] = 'N'\n",
    "        else:\n",
    "            matrix[i][j] = matrix[i][j-1]\n",
    "            b[i][j] = 'W'\n",
    "            \n",
    "d = b[n][m]\n",
    "while d != '':\n",
    "    d = b[i][j]\n",
    "    if d == 'W':\n",
    "        j = j-1\n",
    "    elif d == 'N':\n",
    "        i = i-1\n",
    "    elif d == 'NW':\n",
    "        out = v[i-1] + out\n",
    "        i = i-1\n",
    "        j = j-1\n",
    "\n",
    "filein.close()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## edit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n"
     ]
    }
   ],
   "source": [
    "filein = open('rosalind_edit.txt', encoding = 'UTF-8')\n",
    "l = []\n",
    "i = -1\n",
    "for line in filein:\n",
    "    if '>' in line:\n",
    "        i = i+1\n",
    "        l.append('')\n",
    "        continue\n",
    "    else:\n",
    "        l[i] = l[i] + line.replace('\\n', '')\n",
    "\n",
    "v = l[0]\n",
    "w = l[1]\n",
    "n = len(v)\n",
    "m = len(w)\n",
    "matrix = []\n",
    "\n",
    "for i in range(0, n+1):\n",
    "    matrix.append([0]*(m+1))\n",
    "\n",
    "for i in range(1, n+1):\n",
    "    matrix[i][0] = i\n",
    "for j in range(1, m+1):\n",
    "    matrix[0][j] = j\n",
    "    \n",
    "for i in range(1, n+1):\n",
    "    for j in range(1, m+1):\n",
    "        c = 0 if v[i-1] == w[j-1] else 1\n",
    "        matrix[i][j] = min(matrix[i-1][j-1] + c, matrix[i-1][j] + 1, matrix[i][j-1] + 1)\n",
    "        \n",
    "out = matrix[i][j]\n",
    "filein.close()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## edta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n",
      "WITVLCVAS---H----AFHCCGGTYEI-------D-SNVN-QY-L----NGRVASMRQLS-------NEFWDIMMPF-----G--LELM-DHVRNNQDGKIRNHQQHIANSARRACPMEVGTYNDDVGENNCSTSVTFPLSKELTCYDGEYCHQFESGRRFNS-----WFRVYKKWPKEWHDHQWTGGVPVMYKDDKGMLGHWILYVG----QP-LQDDEWGRQTDPRYIWGAITVTDA---A--WPKQQPYAL-YQSF-LITSMEAWMDAAGPALTPVSI-DAFLQQERQQALNFQTYAHRGESFSNYGCFVYVYTAEQTFSHHSQETTLYRRTKDFSPTQICLSVCGEHPKEGFHCPNIMQNYSMITETPCTAMEHDHSSINCLIEETQPPSVMPCYSTNGRVG----------EELPPPKPMAFTLITVVMQRPPFRQVEH----VEIFPECVHCNELLREMRWIWPWTEMDYKSNIPTSWECASLWLYAYRVCYEYWNMQDVVGAHATVKRGNLNWTSRFSCFPAETNDPQPIHAIELFFRYWKSIESLYGP-MGYNPTWNTEEVMAWHC-MVMDFGATPAGKLISLTINPMRKHWNHNMYMKITGFVWSYVPYQFGNTDWCSATFYPIDYGQGELEFDHDWDLHNYYTVQVMRICRDHRSCLGKVGYGDDFMRGRHDWTTQVWETSESEYYTQQQW--QTKWKLEFKFEPPKKCTLCQM-----V---DEMDCMVQPRWLEWKCQFNDA-GSCKQMKRCECFGHFQRWHYCVEVGDLLDIKNPLTYFNH--GTHNRCNFPCCLNKHMRLQLKFQNPRQERNGENMLIGPRVFFRHMRTPTRRGSTSHFVMTAMRSLRRLYPAAANCIWPTQFLVALNIMCNRTKGL--WRWAHDATKKRPHQKNHMHM---------KKWQAGQVADMNVTQ\n",
      "WITVLCLASGVEHDNQNAFHYCGGTYEIDFRTRFHDSSNVNAEYLLWESHNGRVASMRQLSHPIVTMHYENWDEMVPFTKMSCGDCLELMYKMVRINQDGKIRNPNQHIANS---A--MEV---NENNFKMWC-LKKESP-AKPQTCYDGEYCHQFESGRRFNSPMYGRMFGVYKKWPKWVYDHQWTGGVHTCPTWQKTRMQHSILYVGQQTDQPCRNQDEWGR--KHMYMWGAITVTDARGGAQFWPKPQPYALRDDVFDYHNRMEAWMDAAGPALKPQYIYQAFLQQER--AITTQTYAMRNMDTTDFHCVAAQNVCEFDVYTACQE-TFSDWNWHQNITQICLSV--------FHCPNIMMNYSAITETPCSAMQHDH-S---RFYKSCLPSVMPCYSTNGRVGKVAPLHCCVFNILPPPKPMAFALITVVMQRPPIRQVEHFMRINYIKIFSGMVNELLSEMRWIWPWTEMD-----------A--W-------YEYWNMQDVVGMHATVKRGNLNWTSAFSCFPA-INDPQPIHAIELFFRYWKCVESLYGPCSSHIDGYNPTEVMASHCWAVMDFGATPARKLISLTINP-------IMYMKITGFVWSYVPYAF-----CSAT-------QQEEEFDHDWDLHN-Y---V-WICRDHRVPLGKVGYLDDFGRGRHDWTTQVWETSEHEYYTQQQWEISTKWKLEFKFEPPKKCWWCQMVHYSQVAKDDEMDCMVQNMWLEWKCQFNPAMTQFNLQARCE---YKMR-NY--SWRPSL---NP---FNHEFHTHNRCNFP--L--HMRLQLKFQ--RQERNIENMLIGPRVFFRHMRTPTRR----HFVMTAMRSLRRLYPAAASCIWPTQYLVAPNIMCNRTKGLHDCSWAHDAT-K--EQKNHMHMTDYEPWECCFNWQAGQVAYMNVTQ\n"
     ]
    }
   ],
   "source": [
    "filein = open('rosalind_edta.txt', encoding = 'UTF-8')\n",
    "l = []\n",
    "i = -1\n",
    "for line in filein:\n",
    "    if '>' in line:\n",
    "        i = i+1\n",
    "        l.append('')\n",
    "        continue\n",
    "    else:\n",
    "        l[i] = l[i] + line.replace('\\n', '')\n",
    "\n",
    "s = l[0]\n",
    "t = l[1]\n",
    "m = len(s)\n",
    "n = len(t)\n",
    "matrix = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "for i in range(m + 1):\n",
    "    matrix[i][0] = i\n",
    "for j in range(n + 1):\n",
    "    matrix[0][j] = j\n",
    "for i in range(1, m + 1):\n",
    "    for j in range(1, n + 1):\n",
    "        cost = 0 if s[i - 1] == t[j - 1] else 1\n",
    "        matrix[i][j] = min(matrix[i - 1][j] + 1, \n",
    "                       matrix[i][j - 1] + 1,  \n",
    "                       matrix[i - 1][j - 1] + cost) \n",
    "\n",
    "i = m\n",
    "j = n\n",
    "s1 = []\n",
    "t1 = []\n",
    "while i > 0 or j > 0:\n",
    "    c = 0 if s[i - 1] == t[j - 1] else 1\n",
    "    if i > 0 and j > 0 and matrix[i][j] == matrix[i - 1][j - 1] + c:\n",
    "        s1.append(s[i - 1])\n",
    "        t1.append(t[j - 1])\n",
    "        i -= 1\n",
    "        j -= 1\n",
    "    elif i > 0 and matrix[i][j] == matrix[i - 1][j] + 1:\n",
    "        s1.append(s[i - 1])\n",
    "        t1.append('-')\n",
    "        i -= 1\n",
    "    else:\n",
    "        s1.append('-')\n",
    "        t1.append(t[j - 1])\n",
    "        j -= 1\n",
    "print(matrix[m][n])\n",
    "\n",
    "s1.reverse()\n",
    "out = ''\n",
    "for elem in s1:\n",
    "    out += elem\n",
    "print(out)\n",
    "\n",
    "t1.reverse()\n",
    "out = ''\n",
    "for elem in t1:\n",
    "    out += elem\n",
    "print(out)\n",
    "\n",
    "filein.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ctea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680840\n"
     ]
    }
   ],
   "source": [
    "filein = open('rosalind_ctea.txt', encoding = 'UTF-8')\n",
    "l = []\n",
    "i = -1\n",
    "for line in filein:\n",
    "    if '>' in line:\n",
    "        i = i+1\n",
    "        l.append('')\n",
    "        continue\n",
    "    else:\n",
    "        l[i] = l[i] + line.replace('\\n', '')\n",
    "\n",
    "MOD = 134217727  # requested modulo\n",
    "s = l[0]\n",
    "t = l[1]\n",
    "m = len(s)\n",
    "n = len(t)\n",
    "matrix = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "count = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "for i in range(m + 1):\n",
    "    matrix[i][0] = i\n",
    "    count[i][0] = 1\n",
    "for j in range(n + 1):\n",
    "    matrix[0][j] = j\n",
    "    count[0][j] = 1\n",
    "for i in range(1, m + 1):\n",
    "    for j in range(1, n + 1):\n",
    "        c = 0 if s[i - 1] == t[j - 1] else 1\n",
    "        matrix[i][j] = min(matrix[i - 1][j] + 1, matrix[i][j - 1] + 1, matrix[i - 1][j - 1] + c)\n",
    "        if matrix[i][j] == matrix[i - 1][j] + 1:\n",
    "            count[i][j] += count[i - 1][j]\n",
    "        if matrix[i][j] == matrix[i][j - 1] + 1:\n",
    "            count[i][j] += count[i][j - 1]\n",
    "        if matrix[i][j] == matrix[i - 1][j - 1] + c:\n",
    "            count[i][j] += count[i - 1][j - 1]\n",
    "            \n",
    "        count[i][j] %= MOD\n",
    "\n",
    "print(count[m][n])\n",
    "filein.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2417\n"
     ]
    }
   ],
   "source": [
    "blos = open('BLOSUM.txt', encoding = 'UTF-8')\n",
    "blosum = []\n",
    "for line in blos:\n",
    "    blosum.append(line.replace('\\n', '').split(' '))\n",
    "blos.close()\n",
    "\n",
    "col = []\n",
    "for line in blosum:\n",
    "    col.append(line[0])\n",
    "\n",
    "def getBlosum(c1, c2):\n",
    "    i = blosum[0].index(c1)\n",
    "    j = col.index(c2)\n",
    "    return int(blosum[i][j])\n",
    "\n",
    "\n",
    "filein = open('rosalind_glob.txt', encoding = 'UTF-8')\n",
    "l = []\n",
    "i = -1\n",
    "for line in filein:\n",
    "    if '>' in line:\n",
    "        i = i+1\n",
    "        l.append('')\n",
    "        continue\n",
    "    else:\n",
    "        l[i] = l[i] + line.replace('\\n', '')\n",
    "\n",
    "s = l[0]\n",
    "t = l[1]\n",
    "pgap = -5 \n",
    "\n",
    "n = len(s)\n",
    "m = len(t)\n",
    "matrix = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "for i in range(1, n + 1):\n",
    "    matrix[i][0] = i * pgap\n",
    "for j in range(1, m + 1):\n",
    "    matrix[0][j] = j * pgap\n",
    "for i in range(1, n + 1):\n",
    "    for j in range(1, m + 1):\n",
    "        match = matrix[i - 1][j - 1] + getBlosum(s[i - 1], t[j - 1])\n",
    "        delete = matrix[i - 1][j] + pgap\n",
    "        insert = matrix[i][j - 1] + pgap\n",
    "        matrix[i][j] = max(match, delete, insert)\n",
    "\n",
    "print(matrix[-1][-1])\n",
    "filein.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
